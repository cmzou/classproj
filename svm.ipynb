{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLTSVM\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold # for test-train split & cross validation\n",
    "import random\n",
    "import scipy.sparse as sp\n",
    "import preprocessing\n",
    "\n",
    "# Ensure reproducibility\n",
    "seed = 561\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 unique classes found\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "merged = preprocessing.load_mea()\n",
    "\n",
    "# Constants\n",
    "vec_dim = 100 # how big the word embeddings are\n",
    "# Vectorize\n",
    "docvecs = preprocessing.create_tokens(merged, 'text', vec_dim, 'doc')\n",
    "docvecs_avg = preprocessing.create_tokens(merged, 'text', vec_dim, 'word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add doc embeddings\n",
    "merged = pd.concat([merged, pd.DataFrame(docvecs)], axis=1)\n",
    "merged = pd.concat([merged, pd.DataFrame(docvecs_avg)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dim = 18 # number of distinct classes\n",
    "k_folds = 5 # number of folds for cv\n",
    "num_metrics = 6 # number of metrics -- manually set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Test MLTSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV to find best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split into x and y\n",
    "x_doc = merged.iloc[:, 7+class_dim:7+class_dim+vec_dim]\n",
    "x_word = merged.iloc[:, 7+class_dim+vec_dim:7+class_dim+vec_dim*2]\n",
    "y = merged.iloc[:, 7:7+class_dim]\n",
    "\n",
    "# Using grid search with cv to find best params\n",
    "parameters = {'c_k': [0.0625, 0.125, 2],\n",
    "             'sor_omega': [0.0625, 0.125, 2],\n",
    "             'lambda_param': [0.0625, 0.125, 2]}\n",
    "score = ['accuracy', 'f1_micro'] # note that accuracy here means exact match ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Phoenix\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c_k': 0.0625, 'lambda_param': 2, 'sor_omega': 2} 0.09803921568627451\n"
     ]
    }
   ],
   "source": [
    "# First with the document model\n",
    "clf_doc = GridSearchCV(MLTSVM(), parameters, scoring=score, verbose=0, refit='accuracy', cv=5)\n",
    "clf_doc.fit(sp.csr_matrix(x_doc), sp.csr_matrix(y))\n",
    "\n",
    "print(clf_doc.best_params_, clf_doc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Phoenix\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Phoenix\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Phoenix\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c_k': 0.125, 'lambda_param': 2, 'sor_omega': 0.125} 0.11764705882352941\n"
     ]
    }
   ],
   "source": [
    "# Second with the averaged word vector model\n",
    "clf_word = GridSearchCV(MLTSVM(), parameters, scoring=score, verbose=0, refit='accuracy', cv=5)\n",
    "clf_word.fit(sp.csr_matrix(x_word), sp.csr_matrix(y))\n",
    "\n",
    "print(clf_word.best_params_, clf_word.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cv(x, c_k, sor_omega, lambda_param):\n",
    "    final_scores = np.empty((k_folds, num_metrics))\n",
    "    i=0\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        classifier = MLTSVM(c_k=c_k, sor_omega=sor_omega, lambda_param=lambda_param)\n",
    "        \n",
    "        X_train, X_test = x.iloc[train_index], x.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        # train\n",
    "        classifier.fit(sp.csr_matrix(X_train), sp.csr_matrix(y_train))\n",
    "\n",
    "        # predict\n",
    "        y_pred = classifier.predict(sp.csr_matrix(X_test))\n",
    "\n",
    "        final_scores[i] = preprocessing.calc_metrics(y_test.values, y_pred)\n",
    "        i=i+1\n",
    "    return final_scores.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "cv_scores_doc = run_cv(x_doc, clf_doc.best_params_['c_k'], clf_doc.best_params_['lambda_param'], clf_doc.best_params_['sor_omega'])\n",
    "cv_scores_word = run_cv(x_word, clf_word.best_params_['c_k'], clf_word.best_params_['lambda_param'], clf_word.best_params_['sor_omega'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLTSVM Model with Doc2Vec Results:\n",
      "[0.89001195 0.1172043  0.35531397 0.47171576 0.29046041 0.62590493]\n",
      "\n",
      "MLTSVM Model with Averaged Word2Vec Results:\n",
      "[0.8179092  0.01333333 0.25681993 0.22966048 0.29770652 0.58905486]\n"
     ]
    }
   ],
   "source": [
    "print('MLTSVM Model with Doc2Vec Results:')\n",
    "print(cv_scores_doc) # note that AUC here is meaningless since SVM is not probabilistic\n",
    "print()\n",
    "print('MLTSVM Model with Averaged Word2Vec Results:')\n",
    "print(cv_scores_word) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
